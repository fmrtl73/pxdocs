---
title: Collect diagnostics
weight: 100
keywords: Troubleshoot, diags, phonehome, callhome
description: Find out how to collect diagnostics for a Portworx cluster 
aliases:
    - /portworx-install-with-kubernetes/operate-and-maintain-on-kubernetes/troubleshooting/collecting-diagnostics/
---
## About diagnostics

A Portworx diagnostics bundle (often referred to as just "diags") is a support bundle that contains all the information our support team would need to diagnose an issue in your cluster. It mainly contains:

* Portworx journald logs
* Output from common Portworx CLI command that provide details about cluster, nodes and volumes
* Basic information about the OS of the cluster nods 
* Stack and heap files of Portworx processes
* Alerts generated by the cluster
* Cores or traces from Portworx processes (if found)

## Auto-uploading diags using Pure1 integration

With Portworx 2.8.0 or above, Portworx can now automatically upload its diags to Pure Storage's call home service called **Pure1**. The primary benefits of this are:

* You don't have to copy out diag bundles from your cluster nodes and upload them to support tickets
* When nodes run into issues, they automatically collect diags and call home them. This allows Portworx support to get ahead of the issues and reduces the time to resolution.

When working on a support case, provide your Cluster UUID to Portworx support. They will be able to retrieve your diags from Pure1.

### Find your cluster's UUID?
If you are using operator-based install, you can find this here (See `CLUSTER UUID` column):

```text
kubectl get storagecluster -n kube-system
```
```output
NAME                                              CLUSTER UUID                           STATUS   VERSION           AGE
px-cluster-2ec933a4-29be-440c-b5b1-ec53d3ba5b39   199ccacd-4253-4e57-9a3d-b2249dff3501   Online   01d934d_d03a058   26h
```

Another place to find your cluster's UUID is in the output of `/opt/pwx/bin/pxctl status`.

```text
pxctl status | grep 'Cluster UUID'
```
```output
Cluster UUID: 199ccacd-4253-4e57-9a3d-b2249dff3501
```

## Pre-requisites

* Portworx 2.8.0 or later
* For Operator based installations, Portworx Operator 1.5.0 or above using [the spec generator](https://central.portworx.com/)
* Outbound access to the internet to allow connection to Pure1

## Enable Pure1 integration

Enabling telemetry adds a new `telemetry` sidecar container to Portworx pods. This container is responsible for uploading Portworx diagnostics to Pure1. 

### Fresh installs

Telemetry and metrics collector are disabled by default for all new clusters in Portworx 2.8.0 or later. However, you can enable this function when you generate a StorageCluster spec.

### Upgrades 

If you are upgrading from Portworx version prior to 2.8.0, follow the [Enable Pure1 integration for upgrades](/operations/operate-kubernetes/troubleshooting/enable-pure1-upgrades) page for instructions.

## Collect diagnostics

Portworx diagnostics are collected in primarily 2 ways:

### On demand

This is done via the pxctl CLI. The most common command used here is:

```text
/opt/pwx/bin/pxctl service diags -a
```

This generates the diagnostics bundle on the node. If the Pure1 telemetry is enabled, it will be automatically uploaded to Pure1.

### On crash

If a Portworx process runs into an issue on a node, it will automatically collect diagnostics. If the Pure1 telemetry is enabled, it will be automatically uploaded to Pure1.

## Disable Pure1 integration

#### Operator based install

To disable the metrics collector and telemetry integration, add the following section in your StorageCluster spec:

```text
spec:
  monitoring:
    telemetry:
      enabled: false 
```

This removes the `telemetry` container from the Portworx pod.

#### DaemonSet based install

To disable the metrics collector and telemetry integration for DaemonSet based install, remove the `telemetry` container from the Portworx DaemonSet.

See [Generate a complete diagnostics package](/reference/cli/service/#generate-a-complete-diagnostics-package) for the entire CLI syntax.

